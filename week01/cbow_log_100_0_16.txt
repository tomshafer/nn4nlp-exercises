Namespace(DATADIR='../../data/classes', DROPOUT=0.5, EMBEDDING_SIZE=64, EPOCHS=100)
Vocabulary size = 16581 tokens

CBOWClassifier(
  (embed): Embedding(16581, 64, padding_idx=0)
  (dropout): Dropout(p=0.5, inplace=False)
  (softmax): Linear(in_features=64, out_features=5, bias=True)
)

Training for 100 epochs
Dropout p = 0.500
Embedding dim = 64
Total parameters = 1,061,509

EPOCH 1:
Train: 1.49979 in 4.840 s ↓100.000%  37.5% (   6.8  48.5  12.0  47.9  28.3)
Dev:   1.78937 in 3.182 s ↓100.000%  26.1% (   8.9  41.4   0.0   0.0   0.0)

EPOCH 2:
Train: 1.41782 in 4.690 s ↓  5.466%  41.5% (  16.3  49.9  28.1  49.7  30.9)
Dev:   1.62560 in 3.149 s ↓  9.152%  26.9% (  18.5  41.6   8.6   0.0   0.0)

EPOCH 3:
Train: 1.20175 in 4.728 s ↓ 15.240%  53.5% (  39.0  58.3  47.3  57.6  51.0)
Dev:   1.58237 in 3.173 s ↓  2.659%  29.1% (  20.7  42.7  16.8   9.2   9.0)

EPOCH 4:
Train: 0.99691 in 4.709 s ↓ 17.045%  65.0% (  57.5  67.7  62.1  67.4  63.5)
Dev:   1.58793 in 3.160 s ↑  0.352%  31.5% (  25.7  42.2  23.9  16.3  24.5)

EPOCH 5:
Train: 0.81180 in 4.731 s ↓ 18.568%  73.5% (  69.3  75.8  70.9  74.6  73.4)
Dev:   1.60352 in 3.178 s ↑  0.982%  33.2% (  30.8  42.1  25.6  21.5  32.3)

EPOCH 6:
Train: 0.65652 in 4.730 s ↓ 19.128%  79.3% (  77.6  80.9  77.3  80.1  78.8)
Dev:   1.62989 in 3.180 s ↑  1.645%  33.5% (  32.6  41.1  27.0  24.6  34.3)
Epoch     6: reducing learning rate of group 0 to 1.0000e-04.

EPOCH 7:
